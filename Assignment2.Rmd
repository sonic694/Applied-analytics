---
title: "MATH2406 Applied Analytics"
author: "Student Name - s1234567"
subtitle: 'Assessment 2: Applied Data Project'
output:
  html_document:
    df_print: paged
  html_notebook: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## **Setup**

```{r, echo = TRUE, warnings = FALSE}
# Load all required packages for the assignment
# These packages provide functions for data manipulation, visualization, and statistics

library(dplyr)     # For data manipulation (filter, mutate, etc.)
library(ggplot2)   # For creating professional plots and visualizations
library(knitr)     # For creating nice tables in the report
library(MASS)      # For multivariate normal distribution (mvrnorm function)
library(tidyr)     # For data reshaping

# IMPORTANT: Set the random seed using your student number
# This ensures your results are reproducible (same random numbers each time)
# Replace 1234567 with your actual student number
set.seed(1234567)
```

## **Problem 1: Flu Vaccination Experiment**

This problem examines the effectiveness of flu vaccination using synthetic data from a binomial distribution.

```{r problem1}
# Part (a): Generate synthetic data
# We have 200 adults split into two groups of 100 each

# Define the probabilities of contracting flu for each group
prob_flu_vaccine <- 0.10  # 10% chance with vaccine
prob_flu_placebo <- 0.30  # 30% chance with placebo

# Generate the number who contract flu in each group using binomial distribution
# rbinom(n, size, prob) generates n random values from binomial distribution
# where size is the number of trials and prob is the probability of success
flu_group_A <- rbinom(1, size = 100, prob = prob_flu_vaccine)
flu_group_B <- rbinom(1, size = 100, prob = prob_flu_placebo)

# Calculate those who did NOT contract flu
no_flu_group_A <- 100 - flu_group_A
no_flu_group_B <- 100 - flu_group_B

# Create and display the results table
results_table <- data.frame(
  Condition = c("Contracted the flu", "Did not contract the flu", "TOTAL"),
  Group_A = c(flu_group_A, no_flu_group_A, 100),
  Group_B = c(flu_group_B, no_flu_group_B, 100)
)

# Display the table nicely using kable
kable(results_table, 
      caption = "Flu Vaccination Experiment Results",
      col.names = c("Condition", "Group A (Vaccine)", "Group B (Placebo)"))
```

### Part (b): Analysis based on synthetic data

```{r problem1b}
# (i) Probability that a person receiving placebo will NOT contract flu
# This is calculated as: (number who didn't get flu) / (total in placebo group)
prob_no_flu_placebo <- no_flu_group_B / 100
cat("Estimated probability of NOT contracting flu with placebo:", 
    round(prob_no_flu_placebo, 3), "\n")

# (ii) 95% confidence interval for proportion not contracting flu (placebo group)
# For proportions, we use the normal approximation to the binomial
# Standard error = sqrt(p(1-p)/n)
se_proportion <- sqrt(prob_no_flu_placebo * (1 - prob_no_flu_placebo) / 100)

# For 95% CI, we use z = 1.96 (from standard normal distribution)
z_critical <- 1.96
margin_error <- z_critical * se_proportion

# Calculate confidence interval bounds
ci_lower <- prob_no_flu_placebo - margin_error
ci_upper <- prob_no_flu_placebo + margin_error

cat("\n95% Confidence Interval: [", round(ci_lower, 3), ",", 
    round(ci_upper, 3), "]\n")

cat("\nNon-technical explanation: We are 95% confident that the true proportion",
    "of people who receive the placebo and do not contract flu is between",
    round(ci_lower * 100, 1), "% and", round(ci_upper * 100, 1), "%.",
    "This means if we repeated this experiment many times, about 95% of the",
    "confidence intervals would contain the true proportion.\n")

# (iii) If 40% receive vaccine, what percentage contract flu?
# We use the law of total probability
vaccine_rate <- 0.40
no_vaccine_rate <- 0.60

# Calculate observed flu rates from our data
observed_flu_rate_vaccine <- flu_group_A / 100
observed_flu_rate_placebo <- flu_group_B / 100

# Expected percentage contracting flu
expected_flu_rate <- (vaccine_rate * observed_flu_rate_vaccine + 
                     no_vaccine_rate * observed_flu_rate_placebo)

cat("\nExpected percentage contracting flu:", 
    round(expected_flu_rate * 100, 1), "%\n")

# (iv) Probability of contracting flu at least 3 times in 10 years (vaccinated)
# This uses the binomial distribution with n=10 trials
# P(X >= 3) = 1 - P(X <= 2)
prob_at_least_3 <- 1 - pbinom(2, size = 10, prob = observed_flu_rate_vaccine)

cat("\nProbability of contracting flu at least 3 times in 10 years",
    "(if vaccinated):", round(prob_at_least_3, 3), "\n")
```

## **Problem 2: Exponential Distribution and Central Limit Theorem**

This problem explores how sample means behave when data comes from an exponential distribution.

```{r problem2a}
# Part (a): Generate 1000 observations from exponential distribution
# The exponential distribution has mean = 1/rate
# If mean = 10, then rate = 1/10 = 0.1
exp_mean <- 10
exp_rate <- 1/exp_mean
n_obs <- 1000

# Generate the data
exp_data <- rexp(n_obs, rate = exp_rate)

# (i) Compare sample and population statistics
sample_mean <- mean(exp_data)
sample_sd <- sd(exp_data)

# For exponential distribution: mean = 1/rate, sd = 1/rate
pop_mean <- exp_mean
pop_sd <- exp_mean  # For exponential, sd equals mean

cat("Population vs Sample Statistics:\n")
cat("Population mean:", pop_mean, "| Sample mean:", round(sample_mean, 3), "\n")
cat("Population SD:", pop_sd, "| Sample SD:", round(sample_sd, 3), "\n")
cat("\nDiscussion: The sample statistics are very close to the population",
    "parameters. With 1000 observations, we expect good estimates. The small",
    "differences are due to random sampling variation.\n")

# (ii) Compare histogram with theoretical density
# Create a data frame for plotting
plot_data <- data.frame(x = exp_data)

# Create the plot
p1 <- ggplot(plot_data, aes(x = x)) +
  # Add histogram with density scale (not frequency)
  geom_histogram(aes(y = ..density..), bins = 30, 
                 fill = "lightblue", color = "black", alpha = 0.7) +
  # Add theoretical exponential density curve
  stat_function(fun = dexp, args = list(rate = exp_rate), 
                color = "red", size = 1.5) +
  labs(title = "Sample Data vs Theoretical Exponential Distribution",
       x = "Value", y = "Density") +
  theme_minimal() +
  annotate("text", x = 30, y = 0.08, 
           label = "Red line = Theoretical density", color = "red")

print(p1)

cat("\nDiscussion: The histogram closely matches the theoretical exponential",
    "density curve (red line). Both show the characteristic shape of the",
    "exponential distribution - highest density near zero with a long right tail.",
    "The close match confirms our data generation process is correct.\n")
```

```{r problem2b}
# Part (b): Sample means with n=2
# Generate 1000 sample means, each from 2 observations
n_samples <- 1000
sample_size <- 2

# Create a matrix to store our samples
# Each row will be one sample of size 2
samples_n2 <- matrix(rexp(n_samples * sample_size, rate = exp_rate), 
                     nrow = n_samples, ncol = sample_size)

# Calculate the mean of each sample (row)
sample_means_n2 <- rowMeans(samples_n2)

# Create histogram
p2 <- ggplot(data.frame(means = sample_means_n2), aes(x = means)) +
  geom_histogram(bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Sample Means (n = 2)",
       subtitle = "1000 sample means, each from 2 observations",
       x = "Sample Mean", y = "Frequency") +
  theme_minimal() +
  # Add vertical line at theoretical mean
  geom_vline(xintercept = exp_mean, color = "red", linetype = "dashed", size = 1)

print(p2)

cat("\nCharacteristics of the distribution (n=2):\n")
cat("1. Shape: Still right-skewed but less extreme than original exponential\n")
cat("2. Center: Mean of sample means =", round(mean(sample_means_n2), 3), 
    "(close to population mean of 10)\n")
cat("3. Spread: SD of sample means =", round(sd(sample_means_n2), 3), "\n")
cat("4. The distribution is beginning to look more symmetric than the original",
    "exponential, showing the early effects of the Central Limit Theorem.\n")
```

```{r problem2c}
# Part (c): Sample means with n=30
sample_size <- 30

# Generate samples and calculate means
samples_n30 <- matrix(rexp(n_samples * sample_size, rate = exp_rate), 
                      nrow = n_samples, ncol = sample_size)
sample_means_n30 <- rowMeans(samples_n30)

# Create histogram with normal curve overlay
p3 <- ggplot(data.frame(means = sample_means_n30), aes(x = means)) +
  geom_histogram(aes(y = ..density..), bins = 30, 
                 fill = "lightcoral", color = "black", alpha = 0.7) +
  # Add theoretical normal curve based on CLT
  stat_function(fun = dnorm, 
                args = list(mean = exp_mean, 
                           sd = exp_mean/sqrt(sample_size)), 
                color = "blue", size = 1.5) +
  labs(title = "Distribution of Sample Means (n = 30)",
       subtitle = "1000 sample means with normal curve overlay",
       x = "Sample Mean", y = "Density") +
  theme_minimal() +
  annotate("text", x = 14, y = 0.20, 
           label = "Blue line = Theoretical normal", color = "blue")

print(p3)

cat("\nCharacteristics of the distribution (n=30):\n")
cat("1. Shape: Approximately normal (bell-shaped) - CLT in action!\n")
cat("2. Center: Mean of sample means =", round(mean(sample_means_n30), 3), "\n")
cat("3. Spread: SD of sample means =", round(sd(sample_means_n30), 3), "\n")
cat("4. Theoretical SD (SE) =", round(exp_mean/sqrt(sample_size), 3), "\n")
cat("5. The distribution is now approximately normal, demonstrating the",
    "Central Limit Theorem. Even though the original data was exponential",
    "(highly skewed), the sample means follow a normal distribution when n=30.\n")
```

## **Problem 3: Paired t-test for Package Design**

This problem analyzes whether a new milk container design is more attractive than the current design.

```{r problem3}
# Given information from the study
n_participants <- 20
mean_current <- 7.5
mean_new <- 8.2
sd_difference <- 1.9
mean_difference <- mean_new - mean_current

# Part (a): One-tailed paired t-test
# Null hypothesis: μ_new <= μ_current (no improvement)
# Alternative hypothesis: μ_new > μ_current (new design is better)

# Calculate the t-statistic
# For paired data: t = (mean difference) / (sd difference / sqrt(n))
se_difference <- sd_difference / sqrt(n_participants)
t_statistic <- mean_difference / se_difference

# Degrees of freedom for paired t-test
df <- n_participants - 1

# Calculate p-value for one-tailed test (upper tail)
p_value <- pt(t_statistic, df = df, lower.tail = FALSE)

# Critical value for 5% significance level
alpha <- 0.05
t_critical <- qt(1 - alpha, df = df)

cat("Paired t-test Results:\n")
cat("Mean difference (new - current):", mean_difference, "\n")
cat("Standard error:", round(se_difference, 3), "\n")
cat("t-statistic:", round(t_statistic, 3), "\n")
cat("Critical value (α = 0.05):", round(t_critical, 3), "\n")
cat("p-value:", round(p_value, 4), "\n")
cat("\nConclusion: Since p-value =", round(p_value, 4), "< 0.05,",
    "we reject the null hypothesis.\n")
cat("There is statistically significant evidence that the new design",
    "is more attractive than the current design.\n")
```

### Part (b): Management Advice

```{r problem3b}
cat("\n--- ADVICE TO MANAGEMENT ---\n\n")

cat("Dear Management Team,\n\n")

cat("After analyzing the market research data, I can provide the following insights:\n\n")

cat("KEY FINDING: The new package design shows a statistically significant improvement",
    "in attractiveness compared to the current design (p = ", round(p_value, 3), ").\n\n")

cat("SUPPORTING POINTS:\n\n")

cat("1. EFFECT SIZE: The new design scored 0.7 points higher on average",
    "(8.2 vs 7.5 on a 10-point scale). This represents a 9.3% improvement.\n\n")

cat("2. STATISTICAL CONFIDENCE: With 95% confidence, we can state that the new",
    "design is genuinely more attractive, not just due to random chance.\n\n")

cat("3. PRACTICAL SIGNIFICANCE: An increase from 7.5 to 8.2 moves the design",
    "from 'good' to 'very good' territory, which could translate to increased",
    "shelf appeal and sales.\n\n")

cat("4. STUDY LIMITATIONS:\n")
cat("   - Small sample size (20 participants) - consider larger study for confirmation\n")
cat("   - Participants saw both designs - potential order bias\n")
cat("   - Attractiveness may not directly translate to purchase intent\n\n")

cat("RECOMMENDATION: The data supports proceeding with the new design, but I suggest:\n")
cat("   - Conduct a larger follow-up study including purchase intent questions\n")
cat("   - Consider A/B testing in select stores before full rollout\n")
cat("   - Evaluate the cost-benefit ratio of the packaging change\n\n")

cat("The statistical evidence favors the new design, but business considerations",
    "beyond attractiveness should also guide your decision.\n")
```

## **Problem 4: Bivariate Normal Distribution**

This problem explores hypothesis testing with paired data from a bivariate normal distribution.

```{r problem4a}
# Part (a): Generate 10 pairs of observations
# Parameters for bivariate normal
mu1 <- 50
mu2 <- 55
sigma1 <- 10
sigma2 <- 10
rho <- 0.8  # correlation

# Create mean vector and covariance matrix
mu_vec <- c(mu1, mu2)
# Covariance matrix formula:
# [σ1²      ρσ1σ2  ]
# [ρσ1σ2    σ2²    ]
cov_matrix <- matrix(c(sigma1^2, rho*sigma1*sigma2,
                      rho*sigma1*sigma2, sigma2^2), 
                    nrow = 2, ncol = 2)

# Generate 10 pairs
n_pairs <- 10
data_10 <- mvrnorm(n = n_pairs, mu = mu_vec, Sigma = cov_matrix)
colnames(data_10) <- c("X1", "X2")

# Display the data
cat("Generated 10 pairs of observations:\n")
print(round(data_10, 2))

# (i) Decide on appropriate test
cat("\n(i) Choosing appropriate hypothesis test:\n")

# Check correlation between pairs
obs_correlation <- cor(data_10[,1], data_10[,2])
cat("Observed correlation:", round(obs_correlation, 3), "\n")

cat("\nSince the correlation is high (", round(obs_correlation, 3), 
    "), the observations are paired/dependent.\n")
cat("With n=10 (small sample), we should use a PAIRED T-TEST.\n")
cat("We assume normality of differences, which is reasonable given the data",
    "comes from a bivariate normal distribution.\n")

# (ii) Conduct the test
differences <- data_10[,2] - data_10[,1]
t_test_10 <- t.test(differences, alternative = "two.sided", mu = 0)

cat("\n(ii) Paired t-test results (n=10):\n")
cat("Mean difference:", round(mean(differences), 3), "\n")
cat("t-statistic:", round(t_test_10$statistic, 3), "\n")
cat("p-value:", round(t_test_10$p.value, 3), "\n")
cat("95% CI: [", round(t_test_10$conf.int[1], 3), ",", 
    round(t_test_10$conf.int[2], 3), "]\n")

if(t_test_10$p.value < 0.05) {
  cat("\nConclusion: We reject H0 at the 5% level. The test correctly identifies",
      "a significant difference between the means.\n")
} else {
  cat("\nConclusion: We fail to reject H0 at the 5% level. The test failed to",
      "detect the true difference (Type II error).\n")
}

cat("\nReflection: With only 10 observations, the test has low power to detect",
    "the true difference of 5 units. The true means are μ1=50 and μ2=55.\n")
```

```{r problem4b}
# Part (b): Generate 30 pairs of observations
n_pairs <- 30
data_30 <- mvrnorm(n = n_pairs, mu = mu_vec, Sigma = cov_matrix)
colnames(data_30) <- c("X1", "X2")

# (i) Decide on appropriate test
obs_correlation_30 <- cor(data_30[,1], data_30[,2])
cat("\n(b)(i) With 30 pairs:\n")
cat("Observed correlation:", round(obs_correlation_30, 3), "\n")
cat("Again, high correlation suggests paired data. With n=30, we still use",
    "a PAIRED T-TEST.\n")

# (ii) Conduct the test
differences_30 <- data_30[,2] - data_30[,1]
t_test_30 <- t.test(differences_30, alternative = "two.sided", mu = 0)

cat("\n(ii) Paired t-test results (n=30):\n")
cat("Mean difference:", round(mean(differences_30), 3), "\n")
cat("t-statistic:", round(t_test_30$statistic, 3), "\n")
cat("p-value:", round(t_test_30$p.value, 4), "\n")
cat("95% CI: [", round(t_test_30$conf.int[1], 3), ",", 
    round(t_test_30$conf.int[2], 3), "]\n")

if(t_test_30$p.value < 0.05) {
  cat("\nConclusion: We reject H0 at the 5% level. The test correctly identifies",
      "a significant difference between the means.\n")
} else {
  cat("\nConclusion: We fail to reject H0 at the 5% level. The test failed to",
      "detect the true difference (Type II error).\n")
}
```

```{r problem4c}
# Part (c): Comparison
cat("\n(c) Comparison of results:\n\n")

cat("Sample size effect on test power:\n")
cat("- With n=10: p-value =", round(t_test_10$p.value, 3), "\n")
cat("- With n=30: p-value =", round(t_test_30$p.value, 4), "\n\n")

cat("Key insights:\n")
cat("1. Larger sample size (n=30) provides more power to detect the true difference\n")
cat("2. The standard error decreases with larger n, making the test more sensitive\n")
cat("3. Both tests used the same methodology (paired t-test) due to high correlation\n")
cat("4. The true difference (μ2-μ1 = 5) is more likely to be detected with n=30\n\n")

cat("This demonstrates the importance of adequate sample size in hypothesis testing.",
    "Small samples may fail to detect real effects (Type II error), while larger",
    "samples provide the statistical power needed to identify true differences.\n")
```

## **Problem 5: ANOVA for Promotional Scenarios**

This problem compares three promotional strategies using Analysis of Variance (ANOVA).

```{r problem5a}
# Part (a): Generate sales data with SD = 30
n_stores <- 6  # stores per scenario
n_scenarios <- 3
sd_sales <- 30

# Mean sales for each scenario (in thousands)
mean_scenario1 <- 50  # Catalogue only
mean_scenario2 <- 55  # End of aisle only
mean_scenario3 <- 60  # Both catalogue and end of aisle

# Generate sales data
# Each store's monthly sales is one observation
sales_scenario1 <- rnorm(n_stores, mean = mean_scenario1, sd = sd_sales)
sales_scenario2 <- rnorm(n_stores, mean = mean_scenario2, sd = sd_sales)
sales_scenario3 <- rnorm(n_stores, mean = mean_scenario3, sd = sd_sales)

# Combine into a data frame for analysis
sales_data <- data.frame(
  sales = c(sales_scenario1, sales_scenario2, sales_scenario3),
  scenario = factor(rep(1:3, each = n_stores),
                   labels = c("Catalogue", "Display", "Both"))
)

# Display summary statistics
cat("Summary statistics by scenario (SD = 30):\n")
summary_stats <- sales_data %>%
  group_by(scenario) %>%
  summarise(
    mean = round(mean(sales), 2),
    sd = round(sd(sales), 2),
    min = round(min(sales), 2),
    max = round(max(sales), 2)
  )
print(summary_stats)

# (i) Decide on appropriate test
cat("\n(i) Choosing appropriate test:\n")
cat("- We have 3 independent groups (scenarios)\n")
cat("- Comparing means across multiple groups\n")
cat("- Data is normally distributed (by design)\n")
cat("- Therefore, ONE-WAY ANOVA is the appropriate test\n")

# (ii) Conduct ANOVA
anova_result <- aov(sales ~ scenario, data = sales_data)
anova_summary <- summary(anova_result)

cat("\n(ii) ANOVA Results (SD = 30):\n")
print(anova_summary)

# Extract p-value
p_value_anova <- anova_summary[[1]][["Pr(>F)"]][1]

cat("\nConclusion: ")
if(p_value_anova < 0.05) {
  cat("We reject H0 (p =", round(p_value_anova, 3), "< 0.05).\n")
  cat("There is a statistically significant difference in mean sales",
      "between at least two promotional scenarios.\n")
  
  # Post-hoc test to see which groups differ
  cat("\nPost-hoc analysis (Tukey HSD):\n")
  print(TukeyHSD(anova_result))
} else {
  cat("We fail to reject H0 (p =", round(p_value_anova, 3), "> 0.05).\n")
  cat("There is insufficient evidence of differences in mean sales",
      "between promotional scenarios.\n")
}
```

```{r problem5b}
# Part (b): Repeat with SD = 25
sd_sales_b <- 25

# Generate new sales data with smaller SD
sales_scenario1_b <- rnorm(n_stores, mean = mean_scenario1, sd = sd_sales_b)
sales_scenario2_b <- rnorm(n_stores, mean = mean_scenario2, sd = sd_sales_b)
sales_scenario3_b <- rnorm(n_stores, mean = mean_scenario3, sd = sd_sales_b)

sales_data_b <- data.frame(
  sales = c(sales_scenario1_b, sales_scenario2_b, sales_scenario3_b),
  scenario = factor(rep(1:3, each = n_stores),
                   labels = c("Catalogue", "Display", "Both"))
)

# Summary statistics
cat("\n\nPart (b): Summary statistics by scenario (SD = 25):\n")
summary_stats_b <- sales_data_b %>%
  group_by(scenario) %>%
  summarise(
    mean = round(mean(sales), 2),
    sd = round(sd(sales), 2),
    min = round(min(sales), 2),
    max = round(max(sales), 2)
  )
print(summary_stats_b)

# Conduct ANOVA
anova_result_b <- aov(sales ~ scenario, data = sales_data_b)
anova_summary_b <- summary(anova_result_b)

cat("\nANOVA Results (SD = 25):\n")
print(anova_summary_b)

p_value_anova_b <- anova_summary_b[[1]][["Pr(>F)"]][1]

cat("\nConclusion: ")
if(p_value_anova_b < 0.05) {
  cat("We reject H0 (p =", round(p_value_anova_b, 3), "< 0.05).\n")
  cat("There is a statistically significant difference in mean sales.\n")
} else {
  cat("We fail to reject H0 (p =", round(p_value_anova_b, 3), "> 0.05).\n")
  cat("There is insufficient evidence of differences in mean sales.\n")
}
```

```{r problem5c}
# Part (c): Comparison
cat("\n\n(c) Comparison of results:\n\n")

cat("Effect of variability (SD) on ANOVA results:\n")
cat("- With SD = 30: p-value =", round(p_value_anova, 3), "\n")
cat("- With SD = 25: p-value =", round(p_value_anova_b, 3), "\n\n")

cat("Key insights:\n")
cat("1. Lower variability (SD=25) makes it easier to detect differences between groups\n")
cat("2. The F-statistic is larger when within-group variability is smaller\n")
cat("3. Both analyses test the same hypotheses about mean differences\n")
cat("4. In practice, reducing measurement error or controlling for other factors\n")
cat("   can reduce SD and increase the power to detect real differences\n\n")

cat("Practical implication: When designing experiments, minimizing variability\n")
cat("within groups (through careful control and measurement) increases the\n")
cat("likelihood of detecting true differences between treatments.\n")

# Create visualization to show the effect
cat("\nVisualization of the effect of SD on group separation:\n")

# Combine both datasets for plotting
sales_data$sd_group <- "SD = 30"
sales_data_b$sd_group <- "SD = 25"
combined_data <- rbind(sales_data, sales_data_b)

p_comparison <- ggplot(combined_data, aes(x = scenario, y = sales, fill = scenario)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ sd_group) +
  labs(title = "Sales Distribution by Scenario and Variability Level",
       x = "Promotional Scenario",
       y = "Sales (thousands)",
       fill = "Scenario") +
  theme_minimal() +
  theme(legend.position = "bottom")

print(p_comparison)

cat("\nThe plot shows how reduced variability (SD=25) makes the differences",
    "between groups more apparent and easier to detect statistically.\n")
```

## **Conclusion**

This assignment demonstrated key statistical concepts including:

1. **Binomial Distribution**: Modeling binary outcomes (flu/no flu) and calculating probabilities
2. **Central Limit Theorem**: Sample means become normally distributed regardless of the original distribution
3. **Hypothesis Testing**: Using appropriate tests (t-tests, ANOVA) based on data characteristics
4. **Sample Size Effects**: Larger samples provide more power to detect true differences
5. **Variability Effects**: Lower variability within groups makes it easier to detect between-group differences

These concepts are fundamental to data analysis and help us make informed decisions based on sample data.